<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8" />
	<link rel="icon" href="../favicon.svg" />
	<link rel="alternate" type="application/atom+xml" href="/rss.xml" />
	<meta name="viewport" content="width=device-width, initial-scale=1" />

	<!-- Cache control hints (GitHub Pages workaround) -->
	<meta http-equiv="Cache-Control" content="max-age=31536000" />

	<!-- Preload critical fonts -->
	<link rel="preload" href="../fonts/Inter/InterVariable.woff2" as="font" type="font/woff2"
		crossorigin />
	<link rel="preload" href="../fonts/JetBrainsMono/JetBrainsMono-Regular.woff2" as="font"
		type="font/woff2" crossorigin />

	<!-- Load local font CSS file -->
	<link rel="stylesheet" href="../fonts/fonts.css" />
	<script defer src="https://umami.armanckeser.com/script.js" data-website-id="77762bd1-7833-4f5e-ba7c-aaeba4d7e5aa"></script>

	
		<link href="../_app/immutable/assets/0.B3mFHZ6t.css" rel="stylesheet">
		<link rel="modulepreload" href="../_app/immutable/entry/start.BUOheYJy.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/lRf2npKj.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/BqH-B9yD.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/DQR_r4B4.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/udxmeGBm.js">
		<link rel="modulepreload" href="../_app/immutable/entry/app.DXZVPdS2.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/C1FmrZbK.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/C-JR3Khm.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/DUhq5qQa.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/B6C8Xool.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/Bk-eGPO2.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/BjtfNaWY.js">
		<link rel="modulepreload" href="../_app/immutable/nodes/0.BxcBnsP8.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/D6zQX2g5.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/CXdjidyX.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/BQuTJoZ-.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/Xx_CvMKj.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/PwPRnE0L.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/B2IYLj55.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/qs515LPd.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/B2wnbcVs.js">
		<link rel="modulepreload" href="../_app/immutable/nodes/6.D0t82FxU.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/DlYLqU1e.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/_O5SumNn.js"><!--[--><!--[!--><!--]--> <!----><script nonce="%sveltekit.nonce%">(function setInitialMode(defaultMode, themeColors2) {
  const rootEl = document.documentElement;
  const mode = localStorage.getItem("mode-watcher-mode") || defaultMode;
  const light = mode === "light" || mode === "system" && window.matchMedia("(prefers-color-scheme: light)").matches;
  rootEl.classList[light ? "remove" : "add"]("dark");
  rootEl.style.colorScheme = light ? "light" : "dark";
  if (themeColors2) {
    const themeMetaEl = document.querySelector('meta[name="theme-color"]');
    if (themeMetaEl) {
      themeMetaEl.setAttribute("content", mode === "light" ? themeColors2.light : themeColors2.dark);
    }
  }
  localStorage.setItem("mode-watcher-mode", mode);
})("system");</script><!----><!--]--><!--[--><!--[--><meta name="description" content="My experience with LLMs and why I think they are making me a better engineer"><!--]--> <link rel="canonical"> <meta property="og:type" content="article"> <meta property="og:title" content="LLMs are making me a better engineer"> <meta property="og:description" content="My experience with LLMs and why I think they are making me a better engineer"> <meta property="og:url"> <meta property="og:site_name" content="Armanc Keser"> <meta property="article:published_time" content="2025-04-26"> <meta property="article:author" content="Armanc Keser"> <style>
        /* Anchor link styles */
        .anchor-link {
            opacity: 0;
            color: var(--color-accent);
            margin-left: 0.25rem;
            font-size: 0.75em;
            text-decoration: none;
            transition: opacity 0.2s ease;
            cursor: pointer;
        }
        
        h1:hover .anchor-link,
        h2:hover .anchor-link,
        h3:hover .anchor-link,
        h4:hover .anchor-link,
        h5:hover .anchor-link,
        h6:hover .anchor-link {
            opacity: 1;
        }
    </style><!--]--><title>LLMs are making me a better engineer - Armanc Keser</title>
</head>

<body class="font-sans antialiased" data-sveltekit-preload-data="hover">
	<div style="display: contents"><!--[--><!--[--><!----><!----> <div class="min-h-screen flex flex-col w-full"><header style="view-transition-name: header;" class="sticky top-0 z-50 w-full border-b bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/75 transition-colors duration-300 ease-in-out h-14 px-4 sm:px-8 svelte-1iqdwol" aria-label="Application header"><div class="grid h-full grid-cols-2 sm:grid-cols-3 justify-between items-center gap-4 font-mono text-sm"><div style="view-transition-name: nav;" class="flex items-center gap-2 shrink-0"><a style="view-transition-name: logo;" href="/" class="shrink-0" aria-label="Go to home"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide-icon lucide lucide-computer h-4 w-4" aria-hidden="true"><!--[--><!----><rect width="14" height="8" x="5" y="2" rx="2"><!----></rect><!----><!----><rect width="20" height="8" x="2" y="14" rx="2"><!----></rect><!----><!----><path d="M6 18h2"><!----></path><!----><!----><path d="M12 18h6"><!----></path><!----><!--]--><!----><!----><!----><!----></svg><!----></a> <span class="text-accent shrink-0" aria-hidden="true">│</span> <div class="flex items-center space-x-2 font-mono text-sm"><button class="group glass h-6 w-6 rounded-full p-1 transition-all duration-300 hover:bg-accent/10" aria-label="Toggle theme"><div class="h-full w-full rounded-full bg-accent transition-colors duration-300 group-hover:brightness-110"></div></button> <div class="relative lg:hidden"><button id="mobile-pwd-trigger" class="border-b border-zinc-200 dark:border-zinc-800 text-primary hover:text-accent transition-colors" aria-haspopup="true" aria-expanded="false">pwd</button> <!--[!--><!--]--></div> <div class="hidden lg:block"><!----><nav aria-label="breadcrumb"><!----><ol class="text-muted-foreground flex flex-wrap items-center gap-1.5 break-words text-sm sm:gap-2.5"><!--[--><!----><li class="inline-flex items-center gap-1.5"><!--[!--><!----><!--[!--><a class="border-b border-zinc-200 dark:border-zinc-800 text-primary hover:text-accent transition-colors" href="../"><!---->home<!----></a><!--]--><!----><!--]--><!----></li><!----> <!--[--><!----><li role="presentation" aria-hidden="true" class="[&amp;>svg]:size-3.5"><!--[--><span class="text-muted-foreground">/</span><!----><!--]--></li><!----><!--]--><!----><li class="inline-flex items-center gap-1.5"><!--[!--><!----><!--[!--><a class="border-b border-zinc-200 dark:border-zinc-800 text-primary hover:text-accent transition-colors" href="/writing"><!---->writing<!----></a><!--]--><!----><!--]--><!----></li><!----> <!--[--><!----><li role="presentation" aria-hidden="true" class="[&amp;>svg]:size-3.5"><!--[--><span class="text-muted-foreground">/</span><!----><!--]--></li><!----><!--]--><!----><li class="inline-flex items-center gap-1.5"><!--[--><!----><span role="link" aria-disabled="true" aria-current="page" class="font-normal text-muted-foreground"><!---->better-engineer<!----></span><!----><!--]--><!----></li><!----> <!--[!--><!--]--><!--]--><!----></ol><!----><!----></nav><!----></div></div><!----></div> <div class="hidden sm:flex items-center gap-2 w-full min-w-0 font-mono text-sm svelte-1v3itio"><div class="shrink-0 text-blue-600 dark:text-blue-400 svelte-1v3itio">❯</div> <div class="flex flex-col w-full min-w-0 svelte-1v3itio"><div role="textbox" tabindex="-1" aria-haspopup="listbox" aria-controls="command-suggestions" class="caret-container relative w-full min-w-0 outline-none min-h-[1.5em] whitespace-nowrap text-nowrap block line-height-[1.2em] focus:[box-shadow:none] text-foreground dark:text-foreground empty:before:content-[attr(placeholder)] before:text-muted-foreground before:opacity-100 empty:focus:before:content-[&quot;&quot;] focus:after:inline focus:after:animate-[blink_1s_step-end_infinite] focus:after:content-[&quot;&quot;] focus:after:absolute focus:after:top-[0.2em] focus:after:w-[0.6em] focus:after:h-[1.2em] focus:after:bg-accent [&amp;>br]:hidden svelte-1v3itio" contenteditable="true" placeholder="type a command..." spellcheck="false"></div> <!--[!--><!--]--></div></div><!----> <div style="view-transition-name: header-meta;" class="flex items-center gap-2 shrink-0 justify-self-end"><div class="flex items-center gap-2 text-highlight dark:text-highlight"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide-icon lucide lucide-git-branch h-4 w-4" aria-hidden="true"><!--[--><!----><line x1="6" x2="6" y1="3" y2="15"><!----></line><!----><!----><circle cx="18" cy="6" r="3"><!----></circle><!----><!----><circle cx="6" cy="18" r="3"><!----></circle><!----><!----><path d="M18 9a9 9 0 0 1-9 9"><!----></path><!----><!--]--><!----><!----><!----><!----></svg><!----> <button class="transition-colors hover:text-accent outline outline-[0.5px] outline-zinc-200 dark:outline-zinc-800 rounded-md px-1 py-0.5" aria-label="Toggle theme"><span class="dark:hidden">stable</span> <span class="hidden dark:inline">nightly</span></button> <div class="hidden whitespace-nowrap items-center gap-1 md:flex"><div class="flex items-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide-icon lucide lucide-chevron-up h-3 w-3 p-0" aria-hidden="true"><!--[--><!----><path d="m18 15-6-6-6 6"><!----></path><!----><!--]--><!----><!----><!----><!----></svg><!----> <span class="dark:hidden">0</span> <span class="hidden dark:inline">1</span></div> <span class="text-red-400">!0</span> <span class="text-blue-400">?0</span></div></div> <div class="hidden items-center gap-2 md:flex" aria-live="off" aria-label="Current time"><span class="text-accent" aria-hidden="true">│</span> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide-icon lucide lucide-clock h-4 w-4" aria-hidden="true"><!--[--><!----><circle cx="12" cy="12" r="10"><!----></circle><!----><!----><polyline points="12 6 12 12 16 14"><!----></polyline><!----><!--]--><!----><!----><!----><!----></svg><!----> <span class="animate-fade-in">00:00:00</span></div></div></div></header><!----> <main class="flex-1"><!----><!----> <div class="sticky top-14 z-10 bg-background/80 backdrop-blur border-b border-accent/10"><div class="h-1 bg-accent/5"><div class="h-full bg-gradient-to-r from-transparent to-accent transition-all duration-1" style="width: 0%" aria-hidden="true"></div></div> <div class="container mx-auto px-4 sm:px-8"><div class="font-mono text-xs text-muted-foreground py-1.5 flex items-center gap-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide-icon lucide lucide-clock h-3 w-3"><!--[--><!----><circle cx="12" cy="12" r="10"><!----></circle><!----><!----><polyline points="12 6 12 12 16 14"><!----></polyline><!----><!--]--><!----><!----><!----><!----></svg><!----> <span>READING [0%]</span></div></div></div> <article class="container mx-auto px-4 py-8 md:px-8 md:py-16"><div class="max-w-[85rem] mx-auto flex flex-col lg:flex-row gap-8"><div class="flex-1 max-w-[65ch] lg:max-w-[75ch] xl:max-w-[85ch]"><div class="border-b border-accent/20 pb-4 mb-8"><div class="text-sm text-muted-foreground flex items-center gap-4"><div style="view-transition-name: title--writing-better-engineer;" class="w-fit"><h3 class="text-2xl font-mono font-bold text-primary">LLMs are making me a better engineer</h3></div></div> <!--[--><div style="view-transition-name: desc--writing-better-engineer;" class="w-fit"><p class="text-muted-foreground mt-2 text-sm">My experience with LLMs and why I think they are making me a better engineer</p></div><!--]--></div> <div class="prose dark:prose-invert max-w-none prose-lg // Base typography prose-headings:font-heading prose-headings:tracking-tight prose-headings:scroll-mt-24 prose-strong:text-primary prose-strong:font-semibold prose-lead:text-muted-foreground/80 prose-p:leading-relaxed prose-p:text-muted-foreground // Links hover:prose-a:text-accent prose-a:transition-colors prose-a:duration-300 [&amp;_a]:border-b-2 [&amp;_a]:border-accent/30 [&amp;_a:hover]:border-accent // Exception for anchor links [&amp;_.anchor-link]:border-b-0 // Headings [&amp;_h1]:text-3xl [&amp;_h1]:relative [&amp;_h1]:pb-2 [&amp;_h1]:border-b-0 [&amp;_h1]:scroll-mt-24 [&amp;_h1]:before:content-[''] [&amp;_h1]:before:absolute [&amp;_h1]:before:-bottom-0.5 [&amp;_h1]:before:left-0 [&amp;_h1]:before:w-12 [&amp;_h1]:before:h-px [&amp;_h1]:before:bg-gradient-to-r [&amp;_h1]:before:from-accent [&amp;_h1]:before:to-transparent prose-h2:text-2xl prose-h2:border-b prose-h2:border-accent/10 prose-h2:pb-2 prose-h2:mt-10 prose-h2:opacity-90 prose-h2:scroll-mt-24 prose-h3:text-xl prose-h3:font-semibold prose-h3:opacity-80 prose-h3:scroll-mt-24 // Code blocks prose-code:px-1.5 prose-code:py-1 prose-code:rounded prose-code:font-mono prose-code:text-sm prose-code:border prose-code:border-accent/20 [&amp;_pre]:p-6 [&amp;_pre]:border-2 [&amp;_pre>code]:bg-transparent [&amp;_pre>code]:border-none [&amp;_pre>code]:p-0 prose-pre:rounded-xl prose-pre:border prose-pre:border-accent/20 prose-pre:shadow-sm prose-pre:text-primary prose-pre:bg-background // Blockquotes prose-blockquote:border-l-4 prose-blockquote:border-accent/40 prose-blockquote:pl-4 prose-blockquote:bg-gradient-to-b prose-blockquote:from-background/5 // Images prose-img:rounded-xl prose-img:border prose-img:border-accent/20"><!----><blockquote><p>TLDR: I find that instead of frustrating myself with a sequence of bad attempts by an LLM, a loop
of reading the output, stopping it immediately as I see something wrong or outside my preference,
and editing my original prompt until I get a consistent and quality output is letting me discover my
requirements in an incremental way, leading to quality code, technical writing, and output in
general. This also sharpens my thought process around
requirements. Additionally, having worked on LLM based systems in the past years, I am finding
myself saying things like “this —buzzword technology— is a worse —boring but stable
technology—”, and deeply thinking about incentives, entropy, and first principles problem solving
when communicating around engineering decisions about LLM based systems.
Altogether, to make useful LLM systems and to make LLMs I use useful, I find myself having to become
a better engineer.</p></blockquote> <h2 id="contents">Contents<a aria-hidden="true" tabindex="-1" href="#contents"><span class="anchor-link">#</span></a></h2> <ul><li><a href="#the-question">The Question</a></li> <li><a href="#why-riding-the-hype-wave-carefully-matters">Why riding the hype wave (carefully) matters</a></li> <li><a href="#ai-coding-removes-the-friction-of-starting-and-finishing-projects">AI coding removes the friction of starting and finishing projects</a></li> <li><a href="#the-vibe-coding-trap-more-projects-not-necessarily-better-skills">The “Vibe Coding” Trap: More Projects, Not Necessarily Better Skills</a> <ul><li><a href="#stop-and-regenerate-over-and-over-again">Stop and regenerate over and over again</a></li></ul></li> <li><a href="#recognize-the-artifact-and-try-to-get-it-right-in-one-prompt-not-the-first-one">Recognize the artifact, and try to get it right in one prompt (not the first one)</a></li> <li><a href="#thinking-about-llm-systems-and-trends-around-them">Thinking about LLM systems and trends around them</a></li> <li><a href="#so-are-llms-making-you-a-better-engineer">So, Are LLMs Making <em>You</em> a Better Engineer?</a></li></ul> <h2 id="the-question">The Question<a aria-hidden="true" tabindex="-1" href="#the-question"><span class="anchor-link">#</span></a></h2> <p>I know everyone is tired of hearing, talking, thinking, seeing, thinking, and hearing about AI and
LLMs and if they are good or not… so let me add to the pile.</p> <p>As someone who has paid a yearly subscription fee for Cursor, every time a new article comes out about <a href="https://lucianonooijen.com/blog/why-i-stopped-using-ai-code-editors/" rel="nofollow">people stopping using AI code editors</a>, <a href="https://aftermath.site/ai-video-game-development-art-vibe-coding-midjourney" rel="nofollow">AI being forced on workers who don’t want it</a>, or <a href="https://www.axios.com/2024/06/13/genai-code-mistakes-copilot-gemini-chatgpt?ref=wheresyoured.at" rel="nofollow">how bad AI generated code is</a>, I find myself asking the question: Am I using LLMs in a way beneficial to me? And when I say “beneficial”, I mean that in the most holistic sense, are they making me get more done in a sustainable way? Are they enabling me to do things I couldn’t (or wouldn’t)? Are they improving my skills for the long term? And after some consideration, I think the answer is that LLMs are making me (or forcing me to be) a better engineer.</p> <h2 id="why-riding-the-hype-wave-carefully-matters">Why riding the hype wave (carefully) matters<a aria-hidden="true" tabindex="-1" href="#why-riding-the-hype-wave-carefully-matters"><span class="anchor-link">#</span></a></h2> <p>Let me elaborate. Like many fresh out of the college engineers, I have been actively using and testing any new shiny AI tech that came out (from UI builders to AI native note taking apps to Shopping assistants) in the past 2-3 years. Unlike full-stack or FE engineers who were already tired by the new JS frameworks, or seasoned engineers who already know it’ll probably take a life time for a new tech to replace them and just don’t care, being a junior backend engineer, I had the capacity and will to keep an eye on trends and new technology no matter how overwhelming (approaching burn out soon).</p> <p>Which brings me to the first beneficial point of LLMs: they are the cutting edge, and <strong><em>it is
valuable to speak and think cutting edge</em></strong>. Yes, trend catching and switching frameworks and
applications every day is not sustainable or productive and it is tiring, really, really tiring.
When it comes to making a business or just building things, sticking with the tried and true, honing
your skills instead of jumping ship everyday is the way to go. But, I personally see a lot of value
in thinking about how I can use a new technology to solve an old problem, or even better, something
people don’t even recognize as a problem. Staying on the cutting edge pushes you to develop the
skills to distinguish <strong><em>what is air and what is impactful</em></strong>. It might be a healthier life to
assume any new thing that will be impactful will find its way to you in time, but most change is
derivative and even the slightest original good idea could shape the future of a new technology, or
present an opportunity you can’t find in another time. As an engineer, I find it extremely valuable
that I know what LLMs are actually good or bad at, and even more so that I can have strong opinions
about entire movements (please don’t build your system as multi agent). Most valuably, being on the
edge gives you a chance to identify what an industry might have misidentified and a chance to be the
one to fill the gap.</p> <h2 id="ai-coding-removes-the-friction-of-starting-and-finishing-projects">AI coding removes the friction of starting and finishing projects<a aria-hidden="true" tabindex="-1" href="#ai-coding-removes-the-friction-of-starting-and-finishing-projects"><span class="anchor-link">#</span></a></h2> <p>When it comes to using LLMs, I, like most people, started with the chat interfaces and gradually moved up to specialized systems like <a href="https://chef.convex.dev/" rel="nofollow">chef</a>, <a href="https://vetted.ai/" rel="nofollow">vetted.ai</a> (been using this since they were called Lustre), and AI coding IDEs like Cursor. Side note: I find it interesting and true to experience that Cursor lists ”<em>Cursor lets you breeze through changes by predicting your next edit</em>” as the first feature in their website, as I think that is the part I miss the most when I use a different editor.</p> <p>It took me quite a while to pull the trigger on Cursor, but I finally bought in for a year on
January. What convinced me was observing how AI coding just made me much more likely to start and
finish projects. I would get an idea like “I want to have an app to make hanging things easier and
why not learn 3D on the web on the way” to creating <a href="https://easy-hang.pages.dev/" rel="nofollow">EasyHang</a>,
creating a Slackbot for work that automates the process of deploying to staging by getting approvals
from everyone who has commits on the dev branch, or the website you are reading this on. What AI
Coding allowed me to do, was to turn on some lo-fi music, my walking pad, and just keep asking the
AI to fix things my way until things sort of worked. This workflow later got named “vibe coding”,
and it gets a bad rep, but the truth is that through vibe coding I got to create applications that I
wouldn’t have otherwise. It just made coding for myself, after coding for someone else for an 8 hour
workday, possible and fun.</p> <h2 id="the-vibe-coding-trap-more-projects-not-necessarily-better-skills">The “Vibe Coding” Trap: More Projects, Not Necessarily Better Skills<a aria-hidden="true" tabindex="-1" href="#the-vibe-coding-trap-more-projects-not-necessarily-better-skills"><span class="anchor-link">#</span></a></h2> <p>Just because AI coders made me code more doesn’t mean that they made me a better engineer. And in most of the above cases they didn’t. They made me happier, helped me create things that I will be adding to the “things I am proud of” in the <a href="https://yearcompass.com/" rel="nofollow">year compass</a> I will fill this year (did this section in the last year’s compass give me an existential crisis that lead to my yearly subscription to Cursor? We will never know), but I didn’t really “learn 3D on the web on the way”, I just used it.</p> <h3 id="stop-and-regenerate-over-and-over-again">Stop and regenerate over and over again<a aria-hidden="true" tabindex="-1" href="#stop-and-regenerate-over-and-over-again"><span class="anchor-link">#</span></a></h3> <p>This brings me to a revelation I had a few weeks ago using <a href="https://openwebui.com/" rel="nofollow">OpenWebUI</a> to talk to work allowed LLMs for writing an architectural proposal. I had already written my thoughts in freeform on why and when this architecture would be better, and why it fit our problem space. Unfortunately for me, arguments are better received when they have a certain structure and are accompanied by diagrams and examples, counter examples etc, so I turned to Claude for help.</p> <p>LLMs are notoriously <a href="https://en.wikipedia.org/wiki/AI_slop" rel="nofollow">bad at writing</a>, (<a href="https://eqbench.com/creative_writing.html" rel="nofollow">although maybe they are getting better</a>), so I wasn’t expecting much, and in the first iteration I got what I expected. What I didn’t expect was how impactful it was for me to stop the LLM’s response as soon as I saw something out of order, reword and add new requirements to my question and rerun the generation. Doing this a few turns, I ended up with a proposal with clear structure, short, to the point arguments, specific examples generated based on the context I provided, and helpful diagrams made with <a href="https://mermaid.js.org/" rel="nofollow">mermaid</a>. It even wrote things like</p> <blockquote><p><strong>The [x] approach doesn’t solve the [y] problem—it fragments it across multiple boundaries while adding communication complexity.</strong></p></blockquote> <p>Really understanding the core of my argument and distilling it into a direct point at the end of a
chapter. After a few manual edits, I published the proposal and even got some compliments on the
presentation. Even created a web version by asking the LLM to just make a single page HTML using
prebuilt components from a CDN and vanilla JS. The proposal would not have been close to what it is
if I hadn’t spent days writing and editing the free-form version, gathered context, and knew exactly
what I was trying to achieve, but the output of the LLM did teach me things. It showed me how I
could marry all the dispersed ideas I had into a coherent argument, and it wasn’t by letting the LLM
do what it wants, but by figuring out <strong><em>what I want</em></strong> through forcing myself to come up with the
requirements that would get the LLM to not generate slop. This might sound like a no-brainer, but I
think the easy thing and what most people do is to just write the next prompt correcting the mistakes the LLM made, that
leading to context overloading and even more mistakes, getting frustrated and concluding that LLMs
are terrible for the job at hand.</p> <h2 id="recognize-the-artifact-and-try-to-get-it-right-in-one-prompt-not-the-first-one">Recognize the artifact, and try to get it right in one prompt (not the first one)<a aria-hidden="true" tabindex="-1" href="#recognize-the-artifact-and-try-to-get-it-right-in-one-prompt-not-the-first-one"><span class="anchor-link">#</span></a></h2> <p>Nowadays, I use the same principle when coding with Cursor. I try to identify the “artifact” I would
like the AI to generate, and never let it generate a bad output in the first place. Just reword,
clarify, and restart until its 80% of the way there and do the same on improving the artifact
15% more (i.e. letting the LLM edit the first version repeatedly instead of going through
many, many versions and overwhelming the context), and finally manually edit the remaining 5%.</p> <p>Most LLM applications hope to get some predefined
rules to be enough for the LLM to gather or guess the requirements, but only you know what you want,
and until the LLMs become smarter than you, you have to steer the ship.</p> <h2 id="thinking-about-llm-systems-and-trends-around-them">Thinking about LLM systems and trends around them<a aria-hidden="true" tabindex="-1" href="#thinking-about-llm-systems-and-trends-around-them"><span class="anchor-link">#</span></a></h2> <p>There is a separate part of this argument, about how working on LLM systems and tech around them
also pushes me to think about the parallels between some fundamental software problems engineers
have been working on for decades and problems that the industry frames as new to sell useless tech.
And how important of a skill it is to be able to communicate these thoughts in a careful manner when
most people seem to disagree with you. But this probably warrants
a separate blog post.</p> <h2 id="so-are-llms-making-you-a-better-engineer">So, Are LLMs Making <em>You</em> a Better Engineer?<a aria-hidden="true" tabindex="-1" href="#so-are-llms-making-you-a-better-engineer"><span class="anchor-link">#</span></a></h2> <p>Thank you if you have read until this point, I am new to writing a blog so any feedback is more than welcome. What do you think about my argument? Do LLMs make you a better engineer?</p><!----></div> <div class="font-mono text-sm border-t border-accent/20 pt-4 mt-8"><div class="grid grid-cols-[auto_1fr] gap-x-4 gap-y-2"><span class="text-muted-foreground">LAST_MODIFIED:</span> <span>Apr 25, 2025</span> <!--[--><span class="text-muted-foreground">TAGS:</span> <div class="flex flex-wrap gap-2"><!--[--><span class="font-mono text-xs px-1.5 py-0.5 rounded bg-accent/10 text-accent">#LLMs</span><span class="font-mono text-xs px-1.5 py-0.5 rounded bg-accent/10 text-accent">#engineering</span><!--]--></div><!--]--></div></div> <!--[!--><!--]--><!----></div> <div class="lg:w-64 sticky top-[7.5rem] h-fit"><!--[!--><!--]--><!----></div></div></article><!----><!----></main> <footer class="border-t border-accent/10 py-6 font-mono text-sm"><div class="container mx-auto px-4 md:px-8"><div class="flex flex-col sm:flex-row justify-between items-center gap-4"><div class="text-muted-foreground"><span class="text-highlight">©</span> 2025 Armanc Keser</div> <div class="flex gap-6"><a href="../privacy" class="text-primary border-b border-zinc-200 dark:border-zinc-800 hover:text-accent transition-colors">privacy</a> <a href="../terms" class="text-primary border-b border-zinc-200 dark:border-zinc-800 hover:text-accent transition-colors">terms</a> <a href="https://github.com/armanckeser" class="text-primary border-b border-zinc-200 dark:border-zinc-800 hover:text-accent transition-colors" target="_blank" rel="noopener">github</a></div></div></div></footer><!----></div><!----><!--]--> <!--[!--><!--]--><!--]-->
			
			<script>
				{
					__sveltekit_1uxpwe4 = {
						base: new URL("..", location).pathname.slice(0, -1)
					};

					const element = document.currentScript.parentElement;

					Promise.all([
						import("../_app/immutable/entry/start.BUOheYJy.js"),
						import("../_app/immutable/entry/app.DXZVPdS2.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 6],
							data: [{"type":"data","data":null,"uses":{}},null],
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
</body>

</html>